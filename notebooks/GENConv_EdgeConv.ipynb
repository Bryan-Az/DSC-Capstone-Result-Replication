{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75769199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f51459",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0467db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "local = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b57f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "from config.utils import *\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, GlobalAveragePooling1D\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm.notebook import tqdm\n",
    "import XRootD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1108baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/definitions.yml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    definitions = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "features = definitions['features']\n",
    "spectators = definitions['spectators']\n",
    "labels = definitions['labels']\n",
    "\n",
    "nfeatures = definitions['nfeatures']\n",
    "nspectators = definitions['nspectators']\n",
    "nlabels = definitions['nlabels']\n",
    "ntracks = definitions['ntracks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348156a",
   "metadata": {},
   "source": [
    "## Graph Neural Network (with GENConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc2ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding config path for importing GraphDataset class\n",
    "sys.path.insert(0, \"../config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "204a4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "from GraphDataset import GraphDataset\n",
    "if local:\n",
    "    file_names = ['~/teams/DSC180A_FA21_A00/a11/train/ntuple_merged_10.root']\n",
    "    file_names_test = ['~/teams/DSC180A_FA21_A00/a11/test/ntuple_merged_0.root']\n",
    "else:\n",
    "    file_names = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.root']\n",
    "    file_names_test = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root']\n",
    "\n",
    "graph_dataset = GraphDataset('gdata_train', features, labels, spectators, n_events=1000, n_events_merge=1, \n",
    "                             file_names=file_names)\n",
    "\n",
    "test_dataset = GraphDataset('gdata_test', features, labels, spectators, n_events=2000, n_events_merge=1, \n",
    "                             file_names=file_names_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f4f5a",
   "metadata": {},
   "source": [
    "## Generators for Training, Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52323a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train/validation/test sets\n",
    "\n",
    "import uproot\n",
    "trainroot = uproot.open(file_names[0])\n",
    "traintree = trainroot['deepntuplizer/tree']\n",
    "trainlabels = traintree.arrays(['label_QCD_b', \n",
    "                      'label_QCD_bb', \n",
    "                      'label_QCD_c', \n",
    "                      'label_QCD_cc', \n",
    "                      'label_QCD_others', \n",
    "                      'label_H_bb', \n",
    "                      'sample_isQCD'], \n",
    "                     entry_stop=20000,\n",
    "                     library='np')\n",
    "testroot = uproot.open(file_names_test[0])\n",
    "testtree = testroot['deepntuplizer/tree']\n",
    "testlabels = testtree.arrays(['label_QCD_b', \n",
    "                      'label_QCD_bb', \n",
    "                      'label_QCD_c', \n",
    "                      'label_QCD_cc', \n",
    "                      'label_QCD_others', \n",
    "                      'label_H_bb', \n",
    "                      'sample_isQCD'], \n",
    "                     entry_stop=20000,\n",
    "                     library='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706a3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainlabels['label_H_bb']\n",
    "y_test = testlabels['label_H_bb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30989407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import RandomNodeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e64dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920\n",
      "736\n",
      "184\n",
      "1889\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataListLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def collate(items):\n",
    "    l = sum(items, [])\n",
    "    return Batch.from_data_list(l)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "valid_frac = 0.20\n",
    "full_length = len(graph_dataset)\n",
    "valid_num = int(valid_frac*full_length)\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset, valid_dataset = random_split(graph_dataset, [full_length-valid_num,valid_num])\n",
    "\n",
    "train_loader = DataListLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "train_loader.collate_fn = collate\n",
    "valid_loader = DataListLoader(valid_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "valid_loader.collate_fn = collate\n",
    "test_loader = DataListLoader(test_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "test_loader.collate_fn = collate\n",
    "\n",
    "\n",
    "train_samples = len(train_dataset)\n",
    "valid_samples = len(valid_dataset)\n",
    "test_samples = len(test_dataset)\n",
    "print(full_length)\n",
    "print(train_samples)\n",
    "print(valid_samples)\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4c6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 48\n",
    "hidden = 128\n",
    "outputs = 2\n",
    "#Normalization → ReLU → GraphConv → Addition\n",
    "#class GNN(nn.Module):\n",
    "#    def __init__(self, input_dim = inputs, hidden_dim = hidden, a):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ddb5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GENConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e817f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GENConv_Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, width = hidden, n_inputs = inputs):\n",
    "        super(GENConv_Classifier, self).__init__()\n",
    "        self.width = width\n",
    "        self.act = nn.ReLU\n",
    "\n",
    "        # Initial linear layers\n",
    "        self.nn1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(n_inputs),\n",
    "            self.act(),\n",
    "            nn.Linear(n_inputs, width),\n",
    "            self.act(),\n",
    "            nn.Linear(width, width),\n",
    "            self.act(),\n",
    "            nn.Linear(width, width)                   \n",
    "        )\n",
    "        # Generalized Convolutional layer\n",
    "        self.conv = GENConv(width, width, num_layers=2, t=1, learn_t=True)\n",
    "\n",
    "        # Pre-final linear layers\n",
    "        self.nn2 = nn.Sequential(\n",
    "            nn.Linear(width, width),\n",
    "            self.act(),\n",
    "            nn.Linear(width, width),\n",
    "            self.act(),\n",
    "            nn.Linear(width, width),\n",
    "            self.act(),\n",
    "            nn.Linear(width, width),\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.output = nn.Linear(width, outputs)\n",
    "\n",
    "    def forward(self, X, edge_index, edge_attr):\n",
    "        #Normalization → ReLU → GraphConv → Addition\n",
    "        x0 = X\n",
    "        # input layer\n",
    "        x1 = self.nn1(x0)\n",
    "        #GENConv\n",
    "        x2 = self.conv(x1, edge_index, edge_attr)\n",
    "        # hidden layers\n",
    "        x3 = self.nn2(x2)\n",
    "\n",
    "        # output layer\n",
    "        x = torch.sigmoid(self.output(x3))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cfa7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GENConv_Classifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2e146",
   "metadata": {},
   "source": [
    "## Training/Test Loop as Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c44a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=len(train_loader))\n",
    "    pbar.set_description(f'Training epoch: {epoch:04d}')\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * int(data.train_mask.sum())\n",
    "        total_examples += int(data.train_mask.sum())\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    y_true = {'train': [], 'valid': [], 'test': []}\n",
    "    y_pred = {'train': [], 'valid': [], 'test': []}\n",
    "\n",
    "    pbar = tqdm(total=len(test_loader))\n",
    "    pbar.set_description(f'Evaluating epoch: {epoch:04d}')\n",
    "\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "        for split in y_true.keys():\n",
    "            mask = data[f'{split}_mask']\n",
    "            y_true[split].append(data.y[mask].cpu())\n",
    "            y_pred[split].append(out[mask].cpu())\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    train_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['train'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['train'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "    valid_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['valid'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['valid'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "    test_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['test'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['test'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "    return train_rocauc, valid_rocauc, test_rocauc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee9df31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05217af1bde94bf198987999cb3c5e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_mask'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b6cfe14fffb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_rocauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_rocauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rocauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     print(f'Loss: {loss:.4f}, Train: {train_rocauc:.4f}, '\n\u001b[1;32m      5\u001b[0m           f'Val: {valid_rocauc:.4f}, Test: {test_rocauc:.4f}')\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-5ca27733fad9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m     51\u001b[0m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    loss = train(epoch)\n",
    "    train_rocauc, valid_rocauc, test_rocauc = test()\n",
    "    print(f'Loss: {loss:.4f}, Train: {train_rocauc:.4f}, '\n",
    "          f'Val: {valid_rocauc:.4f}, Test: {test_rocauc:.4f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94afcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
